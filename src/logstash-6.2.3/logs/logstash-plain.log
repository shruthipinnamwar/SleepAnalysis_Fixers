[2018-04-15T19:06:58,269][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/Users/ac044474/workspace/src/logstash-6.2.3/modules/fb_apache/configuration"}
[2018-04-15T19:06:58,294][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/Users/ac044474/workspace/src/logstash-6.2.3/modules/netflow/configuration"}
[2018-04-15T19:06:59,285][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"arcsight", :directory=>"/Users/ac044474/workspace/src/logstash-6.2.3/vendor/bundle/jruby/2.3.0/gems/x-pack-6.2.3-java/modules/arcsight/configuration"}
[2018-04-15T19:06:59,502][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-04-15T19:07:00,191][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-04-15T19:07:00,606][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-04-15T19:07:01,835][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[http://localhost:9200], bulk_path=>"/_xpack/monitoring/_bulk?system_id=logstash&system_api_version=2&interval=1s", manage_template=>false, document_type=>"%{[@metadata][document_type]}", sniffing=>false, user=>"logstash_system", password=><password>, id=>"a4b50edbe2aad18a7706cd3e3535aad87e6690b3684cdd214ad5867fc9dcbce4", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_5df0fc0f-aecf-4384-96b0-4ad478e38bd0", enable_metric=>true, charset=>"UTF-8">, workers=>1, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, action=>"index", ssl_certificate_verification=>true, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-04-15T19:07:01,964][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>".monitoring-logstash", "pipeline.workers"=>1, "pipeline.batch.size"=>2, "pipeline.batch.delay"=>50}
[2018-04-15T19:07:02,351][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://logstash_system:xxxxxx@localhost:9200/]}}
[2018-04-15T19:07:02,373][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://logstash_system:xxxxxx@localhost:9200/, :path=>"/"}
[2018-04-15T19:07:02,693][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://logstash_system:xxxxxx@localhost:9200/"}
[2018-04-15T19:07:02,740][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-04-15T19:07:02,743][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-04-15T19:07:02,764][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["http://localhost:9200"]}
[2018-04-15T19:07:02,872][INFO ][logstash.licensechecker.licensereader] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://logstash_system:xxxxxx@localhost:9200/]}}
[2018-04-15T19:07:02,874][INFO ][logstash.licensechecker.licensereader] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://logstash_system:xxxxxx@localhost:9200/, :path=>"/"}
[2018-04-15T19:07:02,885][WARN ][logstash.licensechecker.licensereader] Restored connection to ES instance {:url=>"http://logstash_system:xxxxxx@localhost:9200/"}
[2018-04-15T19:07:02,894][INFO ][logstash.licensechecker.licensereader] ES Output version determined {:es_version=>6}
[2018-04-15T19:07:02,895][WARN ][logstash.licensechecker.licensereader] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-04-15T19:07:03,015][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>".monitoring-logstash", :thread=>"#<Thread:0x4d1adeb0 sleep>"}
[2018-04-15T19:07:03,292][ERROR][logstash.agent           ] Failed to execute action {:action=>LogStash::PipelineAction::Create/pipeline_id:main, :exception=>"LogStash::ConfigurationError", :message=>"Expected one of #, input, filter, output at line 30, column 2 (byte 769) after ", :backtrace=>["/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/compiler.rb:42:in `compile_imperative'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/compiler.rb:50:in `compile_graph'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/compiler.rb:12:in `block in compile_sources'", "org/jruby/RubyArray.java:2486:in `map'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/compiler.rb:11:in `compile_sources'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/pipeline.rb:51:in `initialize'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/pipeline.rb:169:in `initialize'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/pipeline_action/create.rb:40:in `execute'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:315:in `block in converge_state'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:141:in `with_pipelines'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:312:in `block in converge_state'", "org/jruby/RubyArray.java:1734:in `each'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:299:in `converge_state'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:166:in `block in converge_state_and_update'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:141:in `with_pipelines'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:164:in `converge_state_and_update'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:90:in `execute'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/runner.rb:348:in `block in execute'", "/Users/ac044474/workspace/src/logstash-6.2.3/vendor/bundle/jruby/2.3.0/gems/stud-0.0.23/lib/stud/task.rb:24:in `block in initialize'"]}
[2018-04-15T19:07:03,373][INFO ][logstash.inputs.metrics  ] Monitoring License OK
[2018-04-15T19:07:06,502][ERROR][logstash.agent           ] Failed to execute action {:action=>LogStash::PipelineAction::Create/pipeline_id:main, :exception=>"LogStash::ConfigurationError", :message=>"Expected one of #, input, filter, output at line 30, column 2 (byte 769) after ", :backtrace=>["/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/compiler.rb:42:in `compile_imperative'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/compiler.rb:50:in `compile_graph'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/compiler.rb:12:in `block in compile_sources'", "org/jruby/RubyArray.java:2486:in `map'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/compiler.rb:11:in `compile_sources'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/pipeline.rb:51:in `initialize'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/pipeline.rb:169:in `initialize'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/pipeline_action/create.rb:40:in `execute'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:315:in `block in converge_state'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:141:in `with_pipelines'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:312:in `block in converge_state'", "org/jruby/RubyArray.java:1734:in `each'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:299:in `converge_state'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:166:in `block in converge_state_and_update'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:141:in `with_pipelines'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:164:in `converge_state_and_update'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:105:in `block in execute'", "/Users/ac044474/workspace/src/logstash-6.2.3/vendor/bundle/jruby/2.3.0/gems/stud-0.0.23/lib/stud/interval.rb:18:in `interval'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:94:in `execute'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/runner.rb:348:in `block in execute'", "/Users/ac044474/workspace/src/logstash-6.2.3/vendor/bundle/jruby/2.3.0/gems/stud-0.0.23/lib/stud/task.rb:24:in `block in initialize'"]}
[2018-04-15T19:07:09,443][ERROR][logstash.agent           ] Failed to execute action {:action=>LogStash::PipelineAction::Create/pipeline_id:main, :exception=>"LogStash::ConfigurationError", :message=>"Expected one of #, input, filter, output at line 30, column 2 (byte 769) after ", :backtrace=>["/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/compiler.rb:42:in `compile_imperative'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/compiler.rb:50:in `compile_graph'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/compiler.rb:12:in `block in compile_sources'", "org/jruby/RubyArray.java:2486:in `map'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/compiler.rb:11:in `compile_sources'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/pipeline.rb:51:in `initialize'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/pipeline.rb:169:in `initialize'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/pipeline_action/create.rb:40:in `execute'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:315:in `block in converge_state'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:141:in `with_pipelines'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:312:in `block in converge_state'", "org/jruby/RubyArray.java:1734:in `each'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:299:in `converge_state'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:166:in `block in converge_state_and_update'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:141:in `with_pipelines'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:164:in `converge_state_and_update'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:105:in `block in execute'", "/Users/ac044474/workspace/src/logstash-6.2.3/vendor/bundle/jruby/2.3.0/gems/stud-0.0.23/lib/stud/interval.rb:18:in `interval'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:94:in `execute'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/runner.rb:348:in `block in execute'", "/Users/ac044474/workspace/src/logstash-6.2.3/vendor/bundle/jruby/2.3.0/gems/stud-0.0.23/lib/stud/task.rb:24:in `block in initialize'"]}
[2018-04-15T19:07:12,434][ERROR][logstash.agent           ] Failed to execute action {:action=>LogStash::PipelineAction::Create/pipeline_id:main, :exception=>"LogStash::ConfigurationError", :message=>"Expected one of #, input, filter, output at line 30, column 2 (byte 769) after ", :backtrace=>["/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/compiler.rb:42:in `compile_imperative'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/compiler.rb:50:in `compile_graph'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/compiler.rb:12:in `block in compile_sources'", "org/jruby/RubyArray.java:2486:in `map'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/compiler.rb:11:in `compile_sources'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/pipeline.rb:51:in `initialize'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/pipeline.rb:169:in `initialize'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/pipeline_action/create.rb:40:in `execute'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:315:in `block in converge_state'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:141:in `with_pipelines'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:312:in `block in converge_state'", "org/jruby/RubyArray.java:1734:in `each'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:299:in `converge_state'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:166:in `block in converge_state_and_update'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:141:in `with_pipelines'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:164:in `converge_state_and_update'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:105:in `block in execute'", "/Users/ac044474/workspace/src/logstash-6.2.3/vendor/bundle/jruby/2.3.0/gems/stud-0.0.23/lib/stud/interval.rb:18:in `interval'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:94:in `execute'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/runner.rb:348:in `block in execute'", "/Users/ac044474/workspace/src/logstash-6.2.3/vendor/bundle/jruby/2.3.0/gems/stud-0.0.23/lib/stud/task.rb:24:in `block in initialize'"]}
[2018-04-15T19:07:13,197][ERROR][logstash.inputs.metrics  ] Failed to create monitoring event {:message=>"For path: events. Map keys: [:pipelines, :reloads]", :error=>"LogStash::Instrument::MetricStore::MetricNotFound"}
[2018-04-15T19:07:15,435][ERROR][logstash.agent           ] Failed to execute action {:action=>LogStash::PipelineAction::Create/pipeline_id:main, :exception=>"LogStash::ConfigurationError", :message=>"Expected one of #, input, filter, output at line 30, column 2 (byte 769) after ", :backtrace=>["/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/compiler.rb:42:in `compile_imperative'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/compiler.rb:50:in `compile_graph'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/compiler.rb:12:in `block in compile_sources'", "org/jruby/RubyArray.java:2486:in `map'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/compiler.rb:11:in `compile_sources'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/pipeline.rb:51:in `initialize'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/pipeline.rb:169:in `initialize'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/pipeline_action/create.rb:40:in `execute'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:315:in `block in converge_state'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:141:in `with_pipelines'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:312:in `block in converge_state'", "org/jruby/RubyArray.java:1734:in `each'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:299:in `converge_state'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:166:in `block in converge_state_and_update'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:141:in `with_pipelines'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:164:in `converge_state_and_update'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:105:in `block in execute'", "/Users/ac044474/workspace/src/logstash-6.2.3/vendor/bundle/jruby/2.3.0/gems/stud-0.0.23/lib/stud/interval.rb:18:in `interval'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:94:in `execute'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/runner.rb:348:in `block in execute'", "/Users/ac044474/workspace/src/logstash-6.2.3/vendor/bundle/jruby/2.3.0/gems/stud-0.0.23/lib/stud/task.rb:24:in `block in initialize'"]}
[2018-04-15T19:07:18,429][ERROR][logstash.agent           ] Failed to execute action {:action=>LogStash::PipelineAction::Create/pipeline_id:main, :exception=>"LogStash::ConfigurationError", :message=>"Expected one of #, input, filter, output at line 30, column 2 (byte 769) after ", :backtrace=>["/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/compiler.rb:42:in `compile_imperative'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/compiler.rb:50:in `compile_graph'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/compiler.rb:12:in `block in compile_sources'", "org/jruby/RubyArray.java:2486:in `map'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/compiler.rb:11:in `compile_sources'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/pipeline.rb:51:in `initialize'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/pipeline.rb:169:in `initialize'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/pipeline_action/create.rb:40:in `execute'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:315:in `block in converge_state'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:141:in `with_pipelines'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:312:in `block in converge_state'", "org/jruby/RubyArray.java:1734:in `each'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:299:in `converge_state'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:166:in `block in converge_state_and_update'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:141:in `with_pipelines'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:164:in `converge_state_and_update'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:105:in `block in execute'", "/Users/ac044474/workspace/src/logstash-6.2.3/vendor/bundle/jruby/2.3.0/gems/stud-0.0.23/lib/stud/interval.rb:18:in `interval'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:94:in `execute'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/runner.rb:348:in `block in execute'", "/Users/ac044474/workspace/src/logstash-6.2.3/vendor/bundle/jruby/2.3.0/gems/stud-0.0.23/lib/stud/task.rb:24:in `block in initialize'"]}
[2018-04-15T19:07:21,434][ERROR][logstash.agent           ] Failed to execute action {:action=>LogStash::PipelineAction::Create/pipeline_id:main, :exception=>"LogStash::ConfigurationError", :message=>"Expected one of #, input, filter, output at line 30, column 2 (byte 769) after ", :backtrace=>["/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/compiler.rb:42:in `compile_imperative'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/compiler.rb:50:in `compile_graph'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/compiler.rb:12:in `block in compile_sources'", "org/jruby/RubyArray.java:2486:in `map'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/compiler.rb:11:in `compile_sources'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/pipeline.rb:51:in `initialize'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/pipeline.rb:169:in `initialize'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/pipeline_action/create.rb:40:in `execute'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:315:in `block in converge_state'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:141:in `with_pipelines'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:312:in `block in converge_state'", "org/jruby/RubyArray.java:1734:in `each'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:299:in `converge_state'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:166:in `block in converge_state_and_update'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:141:in `with_pipelines'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:164:in `converge_state_and_update'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:105:in `block in execute'", "/Users/ac044474/workspace/src/logstash-6.2.3/vendor/bundle/jruby/2.3.0/gems/stud-0.0.23/lib/stud/interval.rb:18:in `interval'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:94:in `execute'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/runner.rb:348:in `block in execute'", "/Users/ac044474/workspace/src/logstash-6.2.3/vendor/bundle/jruby/2.3.0/gems/stud-0.0.23/lib/stud/task.rb:24:in `block in initialize'"]}
[2018-04-15T19:07:23,217][ERROR][logstash.inputs.metrics  ] Failed to create monitoring event {:message=>"For path: events. Map keys: [:pipelines, :reloads]", :error=>"LogStash::Instrument::MetricStore::MetricNotFound"}
[2018-04-15T19:07:24,429][ERROR][logstash.agent           ] Failed to execute action {:action=>LogStash::PipelineAction::Create/pipeline_id:main, :exception=>"LogStash::ConfigurationError", :message=>"Expected one of #, input, filter, output at line 30, column 2 (byte 769) after ", :backtrace=>["/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/compiler.rb:42:in `compile_imperative'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/compiler.rb:50:in `compile_graph'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/compiler.rb:12:in `block in compile_sources'", "org/jruby/RubyArray.java:2486:in `map'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/compiler.rb:11:in `compile_sources'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/pipeline.rb:51:in `initialize'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/pipeline.rb:169:in `initialize'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/pipeline_action/create.rb:40:in `execute'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:315:in `block in converge_state'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:141:in `with_pipelines'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:312:in `block in converge_state'", "org/jruby/RubyArray.java:1734:in `each'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:299:in `converge_state'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:166:in `block in converge_state_and_update'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:141:in `with_pipelines'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:164:in `converge_state_and_update'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:105:in `block in execute'", "/Users/ac044474/workspace/src/logstash-6.2.3/vendor/bundle/jruby/2.3.0/gems/stud-0.0.23/lib/stud/interval.rb:18:in `interval'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:94:in `execute'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/runner.rb:348:in `block in execute'", "/Users/ac044474/workspace/src/logstash-6.2.3/vendor/bundle/jruby/2.3.0/gems/stud-0.0.23/lib/stud/task.rb:24:in `block in initialize'"]}
[2018-04-15T19:07:27,433][ERROR][logstash.agent           ] Failed to execute action {:action=>LogStash::PipelineAction::Create/pipeline_id:main, :exception=>"LogStash::ConfigurationError", :message=>"Expected one of #, input, filter, output at line 30, column 2 (byte 769) after ", :backtrace=>["/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/compiler.rb:42:in `compile_imperative'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/compiler.rb:50:in `compile_graph'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/compiler.rb:12:in `block in compile_sources'", "org/jruby/RubyArray.java:2486:in `map'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/compiler.rb:11:in `compile_sources'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/pipeline.rb:51:in `initialize'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/pipeline.rb:169:in `initialize'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/pipeline_action/create.rb:40:in `execute'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:315:in `block in converge_state'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:141:in `with_pipelines'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:312:in `block in converge_state'", "org/jruby/RubyArray.java:1734:in `each'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:299:in `converge_state'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:166:in `block in converge_state_and_update'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:141:in `with_pipelines'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:164:in `converge_state_and_update'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:105:in `block in execute'", "/Users/ac044474/workspace/src/logstash-6.2.3/vendor/bundle/jruby/2.3.0/gems/stud-0.0.23/lib/stud/interval.rb:18:in `interval'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/agent.rb:94:in `execute'", "/Users/ac044474/workspace/src/logstash-6.2.3/logstash-core/lib/logstash/runner.rb:348:in `block in execute'", "/Users/ac044474/workspace/src/logstash-6.2.3/vendor/bundle/jruby/2.3.0/gems/stud-0.0.23/lib/stud/task.rb:24:in `block in initialize'"]}
[2018-04-15T19:07:27,472][WARN ][logstash.runner          ] SIGINT received. Shutting down.
[2018-04-15T19:07:28,866][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>".monitoring-logstash", :thread=>"#<Thread:0x4d1adeb0 run>"}
[2018-04-15T19:08:49,367][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/Users/ac044474/workspace/src/logstash-6.2.3/modules/fb_apache/configuration"}
[2018-04-15T19:08:49,381][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/Users/ac044474/workspace/src/logstash-6.2.3/modules/netflow/configuration"}
[2018-04-15T19:08:50,141][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"arcsight", :directory=>"/Users/ac044474/workspace/src/logstash-6.2.3/vendor/bundle/jruby/2.3.0/gems/x-pack-6.2.3-java/modules/arcsight/configuration"}
[2018-04-15T19:08:50,343][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-04-15T19:08:51,223][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-04-15T19:08:51,574][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-04-15T19:08:53,098][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[http://localhost:9200], bulk_path=>"/_xpack/monitoring/_bulk?system_id=logstash&system_api_version=2&interval=1s", manage_template=>false, document_type=>"%{[@metadata][document_type]}", sniffing=>false, user=>"logstash_system", password=><password>, id=>"a4b50edbe2aad18a7706cd3e3535aad87e6690b3684cdd214ad5867fc9dcbce4", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_2414a8e3-9323-4d25-9efb-44a00017d29d", enable_metric=>true, charset=>"UTF-8">, workers=>1, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, action=>"index", ssl_certificate_verification=>true, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-04-15T19:08:53,179][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>".monitoring-logstash", "pipeline.workers"=>1, "pipeline.batch.size"=>2, "pipeline.batch.delay"=>50}
[2018-04-15T19:08:53,548][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://logstash_system:xxxxxx@localhost:9200/]}}
[2018-04-15T19:08:53,565][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://logstash_system:xxxxxx@localhost:9200/, :path=>"/"}
[2018-04-15T19:08:53,787][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://logstash_system:xxxxxx@localhost:9200/"}
[2018-04-15T19:08:53,841][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-04-15T19:08:53,843][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-04-15T19:08:53,866][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["http://localhost:9200"]}
[2018-04-15T19:08:53,978][INFO ][logstash.licensechecker.licensereader] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://logstash_system:xxxxxx@localhost:9200/]}}
[2018-04-15T19:08:53,979][INFO ][logstash.licensechecker.licensereader] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://logstash_system:xxxxxx@localhost:9200/, :path=>"/"}
[2018-04-15T19:08:53,985][WARN ][logstash.licensechecker.licensereader] Restored connection to ES instance {:url=>"http://logstash_system:xxxxxx@localhost:9200/"}
[2018-04-15T19:08:53,991][INFO ][logstash.licensechecker.licensereader] ES Output version determined {:es_version=>6}
[2018-04-15T19:08:53,991][WARN ][logstash.licensechecker.licensereader] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-04-15T19:08:54,102][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>".monitoring-logstash", :thread=>"#<Thread:0x20077082 sleep>"}
[2018-04-15T19:08:55,023][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//localhost:9200], index=>"bulk_sleep_logs", document_type=>"bulk_sleep_logs", user=>"elastic", password=><password>, id=>"08b5d120005b32cdf8b1b6125b0289232b5efb548579fdc910751156b63bfc87", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_a38555a6-21bb-4381-9ebc-c47ea0abe006", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-04-15T19:08:55,120][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-04-15T19:08:55,172][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://elastic:xxxxxx@localhost:9200/]}}
[2018-04-15T19:08:55,176][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://elastic:xxxxxx@localhost:9200/, :path=>"/"}
[2018-04-15T19:08:55,296][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://elastic:xxxxxx@localhost:9200/"}
[2018-04-15T19:08:55,304][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-04-15T19:08:55,305][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-04-15T19:08:55,308][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-04-15T19:08:55,331][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-04-15T19:08:55,349][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//localhost:9200"]}
[2018-04-15T19:08:56,079][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x247b0c52 sleep>"}
[2018-04-15T19:08:56,170][INFO ][logstash.agent           ] Pipelines running {:count=>2, :pipelines=>[".monitoring-logstash", "main"]}
[2018-04-15T19:08:56,188][INFO ][logstash.inputs.metrics  ] Monitoring License OK
[2018-04-15T19:08:57,734][WARN ][logstash.outputs.elasticsearch] Could not index event to Elasticsearch. {:status=>400, :action=>["index", {:_id=>nil, :_index=>"bulk_sleep_logs", :_type=>"bulk_sleep_logs", :_routing=>nil}, #<LogStash::Event:0x3c5af1fa>], :response=>{"index"=>{"_index"=>"bulk_sleep_logs", "_type"=>"bulk_sleep_logs", "_id"=>"O-HIy2IBET4D9aqzfw1u", "status"=>400, "error"=>{"type"=>"mapper_parsing_exception", "reason"=>"failed to parse [Date]", "caused_by"=>{"type"=>"illegal_argument_exception", "reason"=>"Invalid format: \"31.06.2015\" is malformed at \".06.2015\""}}}}}
[2018-04-15T19:08:57,735][WARN ][logstash.outputs.elasticsearch] Could not index event to Elasticsearch. {:status=>400, :action=>["index", {:_id=>nil, :_index=>"bulk_sleep_logs", :_type=>"bulk_sleep_logs", :_routing=>nil}, #<LogStash::Event:0x6ce6bae4>], :response=>{"index"=>{"_index"=>"bulk_sleep_logs", "_type"=>"bulk_sleep_logs", "_id"=>"5-HIy2IBET4D9aqzfw1v", "status"=>400, "error"=>{"type"=>"mapper_parsing_exception", "reason"=>"failed to parse [Date]", "caused_by"=>{"type"=>"illegal_argument_exception", "reason"=>"Invalid format: \"31.06.2016\" is malformed at \".06.2016\""}}}}}
[2018-04-15T19:08:57,736][WARN ][logstash.outputs.elasticsearch] Could not index event to Elasticsearch. {:status=>400, :action=>["index", {:_id=>nil, :_index=>"bulk_sleep_logs", :_type=>"bulk_sleep_logs", :_routing=>nil}, #<LogStash::Event:0x27524671>], :response=>{"index"=>{"_index"=>"bulk_sleep_logs", "_type"=>"bulk_sleep_logs", "_id"=>"m-HIy2IBET4D9aqzfw5x", "status"=>400, "error"=>{"type"=>"mapper_parsing_exception", "reason"=>"failed to parse [Date]", "caused_by"=>{"type"=>"illegal_argument_exception", "reason"=>"Invalid format: \"Date\""}}}}}
[2018-04-15T19:15:05,258][WARN ][logstash.runner          ] SIGINT received. Shutting down.
[2018-04-15T19:15:06,707][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>".monitoring-logstash", :thread=>"#<Thread:0x20077082 run>"}
[2018-04-15T19:15:08,148][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x247b0c52 run>"}
